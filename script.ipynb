{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0385f08-033b-400f-b49b-f84a17424e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ai/lib/python3.12/site-packages/openpyxl/reader/workbook.py:118: UserWarning: Print area cannot be set to Defined name: 'Wedding budget'!$A:$K.\n",
      "  warn(f\"Print area cannot be set to Defined name: {defn.value}.\")\n",
      "/opt/anaconda3/envs/ai/lib/python3.12/site-packages/openpyxl/worksheet/header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n",
      "/opt/anaconda3/envs/ai/lib/python3.12/site-packages/openpyxl/worksheet/header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n",
      "/opt/anaconda3/envs/ai/lib/python3.12/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "üìÑ Processing files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 14.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              file_name  page_number  chunk_number  \\\n",
      "0  Dataset summaries and citations.docx            1             1   \n",
      "1  Dataset summaries and citations.docx            1             2   \n",
      "2  Dataset summaries and citations.docx            1             3   \n",
      "3  Dataset summaries and citations.docx            1             4   \n",
      "4    Ocean_ecogeochemistry_A_review.pdf            1             1   \n",
      "\n",
      "                                                text  \n",
      "0  Table 1. Description of studies included in th...  \n",
      "1  bock, Texas. Agronomy Journal, 112(1), 148‚Äì157...  \n",
      "2  2010). Soil Organic Carbon Input from Urban Tu...  \n",
      "3   (2018). Soil carbon and nitrogen accumulation...  \n",
      "4  327\\nOceanography and Marine Biology: An Annua...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import fitz  # PyMuPDF\n",
    "import docx\n",
    "import csv\n",
    "from tqdm import tqdm  # üëà import tqdm\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "max_tokens_per_chunk = 500\n",
    "\n",
    "def chunk_text(text, max_tokens=500):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    return [tokenizer.decode(tokens[i:i + max_tokens]) for i in range(0, len(tokens), max_tokens)]\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    doc = fitz.open(file_path)\n",
    "    return [page.get_text() for page in doc]\n",
    "\n",
    "def extract_text_from_docx(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    return [\"\\n\".join(para.text for para in doc.paragraphs)]\n",
    "\n",
    "def extract_text_from_csv(file_path):\n",
    "    with open(file_path, encoding=\"utf-8\") as f:\n",
    "        return [f.read()]\n",
    "\n",
    "def extract_text_from_excel(file_path):\n",
    "    df = pd.read_excel(file_path, sheet_name=None)\n",
    "    pages = []\n",
    "    for sheet, data in df.items():\n",
    "        pages.append(f\"Sheet: {sheet}\\n\" + data.to_string(index=False))\n",
    "    return pages\n",
    "\n",
    "def extract_text(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    if ext == \".pdf\":\n",
    "        return extract_text_from_pdf(file_path)\n",
    "    elif ext == \".docx\":\n",
    "        return extract_text_from_docx(file_path)\n",
    "    elif ext in [\".csv\"]:\n",
    "        return extract_text_from_csv(file_path)\n",
    "    elif ext in [\".xls\", \".xlsx\", \".xlsm\"]:\n",
    "        return extract_text_from_excel(file_path)\n",
    "    else:\n",
    "        print(f\"Unsupported file type: {ext}\")\n",
    "        return []\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    all_chunks = []\n",
    "    file_list = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "    for filename in tqdm(file_list, desc=\"üìÑ Processing files\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        try:\n",
    "            pages = extract_text(file_path)\n",
    "            for page_num, text in enumerate(pages, 1):\n",
    "                chunks = chunk_text(text)\n",
    "                for chunk_num, chunk in enumerate(chunks, 1):\n",
    "                    all_chunks.append({\n",
    "                        \"file_name\": filename,\n",
    "                        \"page_number\": page_num,\n",
    "                        \"chunk_number\": chunk_num,\n",
    "                        \"text\": chunk\n",
    "                    })\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {filename}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(all_chunks)\n",
    "\n",
    "# üîç Usage\n",
    "folder_path = \"/Users/yasir/Desktop/Project/Dr.X Files\"\n",
    "df = process_folder(folder_path)\n",
    "print(df.head())\n",
    "df.to_csv(\"all_chunked_text.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e10b4fee-5115-485c-b334-1975a48391b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import tiktoken\n",
    "import ollama\n",
    "import re\n",
    "from tqdm import tqdm  # ‚úÖ Added tqdm for progress bars\n",
    "\n",
    "# ========== Embedding Setup ==========\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "performance_log = []\n",
    "\n",
    "# ========== Performance Logger ==========\n",
    "def log_performance(stage, text_or_token_list, start_time, end_time):\n",
    "    if isinstance(text_or_token_list, list) and isinstance(text_or_token_list[0], int):\n",
    "        total_tokens = len(text_or_token_list)\n",
    "    else:\n",
    "        total_tokens = len(tokenizer.encode(text_or_token_list))\n",
    "\n",
    "    elapsed = end_time - start_time\n",
    "    tokens_per_sec = total_tokens / elapsed if elapsed > 0 else 0\n",
    "\n",
    "    log_entry = {\n",
    "        \"stage\": stage,\n",
    "        \"tokens\": total_tokens,\n",
    "        \"duration_sec\": round(elapsed, 4),\n",
    "        \"tokens_per_sec\": round(tokens_per_sec, 2),\n",
    "        \"timestamp\": pd.Timestamp.now()\n",
    "    }\n",
    "\n",
    "    performance_log.append(log_entry)\n",
    "    print(f\"üìä [{stage}] {total_tokens} tokens in {elapsed:.2f}s ‚Üí {tokens_per_sec:.2f} tokens/sec\")\n",
    "\n",
    "    return tokens_per_sec\n",
    "\n",
    "def export_log(filename=\"performance_log.csv\"):\n",
    "    df = pd.DataFrame(performance_log)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"‚úÖ Performance log saved to {filename}\")\n",
    "\n",
    "def summarize_performance():\n",
    "    df = pd.DataFrame(performance_log)\n",
    "    if df.empty:\n",
    "        print(\"‚ö†Ô∏è No performance data to summarize.\")\n",
    "        return\n",
    "    summary = df.groupby(\"stage\")[\"tokens_per_sec\"].agg([\"count\", \"min\", \"max\", \"mean\"]).reset_index()\n",
    "    print(\"\\nüìà Performance Summary:\")\n",
    "    print(summary.to_string(index=False))\n",
    "    return summary\n",
    "\n",
    "# ========== Preprocessing DataFrame ==========\n",
    "def remove_tables_and_numeric_lines(text):\n",
    "    lines = text.splitlines()\n",
    "    filtered_lines = []\n",
    "    tables_and_numbers = []\n",
    "\n",
    "    for line in lines:\n",
    "        stripped = line.strip().lower()\n",
    "\n",
    "        # Skip short chemical/symbol lines like \"CO\", \"‚áå\", \"+\", etc.\n",
    "        if len(line.strip()) < 10 and re.match(r\"^[A-Za-z0-9()+‚àí‚áå\\\\s]*$\", line):\n",
    "            tables_and_numbers.append(line)\n",
    "            continue\n",
    "        # Remove lines like '.348136          NaN                                                              NaN'\n",
    "        if re.fullmatch(r\"[.\\d\\s]+nan\\s*nan\", line.strip().lower()):\n",
    "            tables_and_numbers.append(line)\n",
    "            continue\n",
    "        # Remove lines like '.348136          NaN    NaN' or 'NaN                  0'\n",
    "        if re.fullmatch(r\"[.\\d\\s]*nan\\s*\\d*\", line.strip().lower()):\n",
    "            tables_and_numbers.append(line)\n",
    "            continue\n",
    "\n",
    "\n",
    "        # Skip lines that are too short and contain mostly numbers\n",
    "        if len(line.strip()) < 40 and sum(c.isdigit() for c in line) / max(len(line), 1) > 0.3:\n",
    "            tables_and_numbers.append(line)\n",
    "            continue\n",
    "        stripped = line.strip().lower()\n",
    "\n",
    "        numbers = re.findall(r\"\\d\", line)\n",
    "        if len(numbers) / max(len(line), 1) > 0.4:\n",
    "            tables_and_numbers.append(line)\n",
    "            continue\n",
    "\n",
    "        if re.search(r\"\\t\", line) or re.search(r\"\\|\", line):\n",
    "            tables_and_numbers.append(line)\n",
    "            continue\n",
    "\n",
    "        if len(re.findall(r\"\\s{2,}\", line)) > 2:\n",
    "            tables_and_numbers.append(line)\n",
    "            continue\n",
    "\n",
    "        if any(keyword in stripped for keyword in [\"author\", \"editor\", \"publisher\", \"published by\", \"phone\", \"email\", \"contact\", \"address\"]):\n",
    "            continue\n",
    "\n",
    "        if re.search(r\"\\b\\w+@\\w+\\.\\w+\\b\", line):\n",
    "            continue\n",
    "        if re.search(r\"\\+?\\d[\\d\\s().-]{7,}\\d\", line):\n",
    "            continue\n",
    "\n",
    "        filtered_lines.append(line)\n",
    "\n",
    "    return \"\\n\".join(filtered_lines), \"\\n\".join(tables_and_numbers)\n",
    "    \n",
    "# ========== DataFrame Cleaning ==========\n",
    "def clean_dataframe_text(df):\n",
    "    df = df.dropna(subset=['text'])  # üßπ Drop rows where 'text' is NaN\n",
    "    df = df[df['text'].str.strip().astype(bool)]  # üßπ Drop rows where 'text' is empty or only whitespace\n",
    "    df = df[df['text'].str.len() >= 10]  # üßπ Drop rows where 'text' is too short\n",
    "    df = df.dropna(subset=['text'])  # üßπ Drop rows where 'text' is NaN\n",
    "    df = df.dropna(subset=['text'])  # üßπ Drop rows where 'text' is NaN\n",
    "    df = df[df['text'].str.strip().astype(bool)]  # üßπ Drop rows where 'text' is empty or only whitespace\n",
    "    df = df[df['text'].str.strip().astype(bool)]  # üßπ Drop rows where 'text' is empty or only whitespace\n",
    "    cleaned_rows = []\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"üßπ Cleaning text in DataFrame\"):\n",
    "        cleaned_text, _ = remove_tables_and_numeric_lines(row['text'])\n",
    "        cleaned_rows.append({\n",
    "            \"file_name\": row['file_name'],\n",
    "            \"page_number\": row['page_number'],\n",
    "            \"chunk_number\": row['chunk_number'],\n",
    "            \"text\": cleaned_text\n",
    "        })\n",
    "        cleaned_df = pd.DataFrame(cleaned_rows)\n",
    "    cleaned_df = cleaned_df[cleaned_df['text'].str.strip().astype(bool)]  # üßπ Drop rows with empty cleaned text\n",
    "    return cleaned_df\n",
    "\n",
    "\n",
    "\n",
    "# ========== Embedding Function ==========\n",
    "def embed_texts_local(texts):\n",
    "    start = time.time()\n",
    "    embeddings = embed_model.encode(texts).tolist()\n",
    "    end = time.time()\n",
    "    log_performance(\"embedding\", \" \".join(texts), start, end)\n",
    "    return embeddings\n",
    "\n",
    "# ========== Store to ChromaDB ==========\n",
    "def store_df_in_chromadb_local(df, persist_dir=\"./chroma_storage\", collection_name=\"cleaned_docs\"):\n",
    "    chroma_client = chromadb.PersistentClient(path=persist_dir)\n",
    "    collection = chroma_client.get_or_create_collection(name=collection_name)\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"üîÅ Storing in ChromaDB\"):\n",
    "        doc_id = f\"{row['file_name']}_{row['page_number']}_{row['chunk_number']}\"\n",
    "        try:\n",
    "            embedding = embed_texts_local([row['text']])[0]\n",
    "            collection.add(\n",
    "                documents=[row['text']],\n",
    "                ids=[doc_id],\n",
    "                metadatas=[{\n",
    "                    \"file_name\": row['file_name'],\n",
    "                    \"page\": row['page_number'],\n",
    "                    \"chunk\": row['chunk_number']\n",
    "                }],\n",
    "                embeddings=[embedding]\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error at row {idx}: {e}\")\n",
    "    print(\"‚úÖ Chunks stored in ChromaDB using local embeddings.\")\n",
    "\n",
    "# ========== Ask Mistral via Ollama ==========\n",
    "def ask_mistral(question, context):\n",
    "    prompt = f\"\"\"\"Write a clear, formal, human-like summary in academic tone.\n",
    "    \n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    start = time.time()\n",
    "    response = ollama.chat(\n",
    "        model=\"mistral\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    end = time.time()\n",
    "    log_performance(\"RAG\", prompt, start, end)\n",
    "    return response['message']['content']\n",
    "\n",
    "# ========== RAG Pipeline ==========\n",
    "def rag_query(question, collection_name=\"cleaned_docs\", persist_dir=\"./chroma_storage\", top_k=1):\n",
    "    query_vector = embed_texts_local([question])[0]\n",
    "\n",
    "    chroma_client = chromadb.PersistentClient(path=persist_dir)\n",
    "    collection = chroma_client.get_or_create_collection(name=collection_name)\n",
    "    results = collection.query(query_embeddings=[query_vector], n_results=top_k)\n",
    "\n",
    "    retrieved_chunks = results[\"documents\"][0]\n",
    "    context = \"\\n\\n\".join(retrieved_chunks)\n",
    "\n",
    "    return ask_mistral(question, context)\n",
    "\n",
    "# ========== Summarize All Documents ==========\n",
    "def summarize_all_documents(collection_name=\"cleaned_docs\", persist_dir=\"./chroma_storage\"):\n",
    "    \"\"\"\n",
    "    Summarize all chunks grouped by document ID.\n",
    "    \"\"\"\n",
    "    chroma_client = chromadb.PersistentClient(path=persist_dir)\n",
    "    collection = chroma_client.get_or_create_collection(name=collection_name)\n",
    "\n",
    "    results = collection.get(include=[\"documents\", \"metadatas\"])\n",
    "    summaries_by_file = {}\n",
    "\n",
    "    for doc, meta in zip(results[\"documents\"], results[\"metadatas\"]):\n",
    "        file_name = meta.get(\"file_name\", \"unknown\")\n",
    "        text = doc if isinstance(doc, str) else doc[0]\n",
    "        if file_name not in summaries_by_file:\n",
    "            summaries_by_file[file_name] = []\n",
    "        summaries_by_file[file_name].append(text)\n",
    "\n",
    "    final_summaries = {}\n",
    "    for file, chunks in tqdm(list(summaries_by_file.items())[:1], desc=\"üß† Summarizing files\"):\n",
    "        combined_text = \"\\n\\n\".join(chunks)\n",
    "        summary = ask_mistral(\"Summarize all the chunks of this document.\", combined_text)\n",
    "        final_summaries[file] = summary\n",
    "\n",
    "    return final_summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32a7c1de-6e47-4680-85fd-4110a8869e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üßπ Cleaning text in DataFrame: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 423/423 [00:00<00:00, 2223.02it/s]\n",
      "üîÅ Storing in ChromaDB:   0%|                   | 1/407 [00:00<02:20,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 154 tokens in 0.25s ‚Üí 618.58 tokens/sec\n",
      "üìä [embedding] 185 tokens in 0.04s ‚Üí 4325.06 tokens/sec\n",
      "üìä [embedding] 32 tokens in 0.04s ‚Üí 811.68 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:   2%|‚ñé                  | 8/407 [00:00<00:23, 17.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 276 tokens in 0.04s ‚Üí 6534.55 tokens/sec\n",
      "üìä [embedding] 442 tokens in 0.01s ‚Üí 31564.58 tokens/sec\n",
      "üìä [embedding] 249 tokens in 0.04s ‚Üí 5795.81 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.01s ‚Üí 37721.69 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 36640.44 tokens/sec\n",
      "üìä [embedding] 143 tokens in 0.04s ‚Üí 3839.78 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:   3%|‚ñç                 | 11/407 [00:00<00:19, 20.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 498 tokens in 0.01s ‚Üí 33532.88 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 33160.75 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 32654.73 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.01s ‚Üí 39987.05 tokens/sec\n",
      "üìä [embedding] 369 tokens in 0.01s ‚Üí 30523.58 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:   5%|‚ñä                 | 19/407 [00:01<00:19, 19.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 130 tokens in 0.28s ‚Üí 458.69 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.02s ‚Üí 30188.80 tokens/sec\n",
      "üìä [embedding] 171 tokens in 0.04s ‚Üí 4659.16 tokens/sec\n",
      "üìä [embedding] 439 tokens in 0.01s ‚Üí 29746.84 tokens/sec\n",
      "üìä [embedding] 494 tokens in 0.01s ‚Üí 33250.73 tokens/sec\n",
      "üìä [embedding] 163 tokens in 0.04s ‚Üí 4229.36 tokens/sec\n",
      "üìä [embedding] 493 tokens in 0.01s ‚Üí 33358.48 tokens/sec\n",
      "üìä [embedding] 317 tokens in 0.01s ‚Üí 25158.84 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:   7%|‚ñà‚ñè                | 28/407 [00:01<00:13, 27.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 186 tokens in 0.04s ‚Üí 4811.79 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.02s ‚Üí 33155.50 tokens/sec\n",
      "üìä [embedding] 308 tokens in 0.02s ‚Üí 17480.29 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.01s ‚Üí 34238.09 tokens/sec\n",
      "üìä [embedding] 315 tokens in 0.01s ‚Üí 26505.75 tokens/sec\n",
      "üìä [embedding] 157 tokens in 0.04s ‚Üí 4162.59 tokens/sec\n",
      "üìä [embedding] 496 tokens in 0.01s ‚Üí 33075.37 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 33505.65 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:   9%|‚ñà‚ñå                | 36/407 [00:01<00:13, 28.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 90 tokens in 0.04s ‚Üí 2178.18 tokens/sec\n",
      "üìä [embedding] 464 tokens in 0.02s ‚Üí 26587.21 tokens/sec\n",
      "üìä [embedding] 214 tokens in 0.04s ‚Üí 5119.85 tokens/sec\n",
      "üìä [embedding] 444 tokens in 0.01s ‚Üí 33782.08 tokens/sec\n",
      "üìä [embedding] 249 tokens in 0.04s ‚Üí 6127.45 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.01s ‚Üí 35177.40 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 35546.76 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  11%|‚ñà‚ñâ                | 44/407 [00:01<00:11, 31.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 498 tokens in 0.01s ‚Üí 35762.21 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 35653.12 tokens/sec\n",
      "üìä [embedding] 63 tokens in 0.04s ‚Üí 1447.98 tokens/sec\n",
      "üìä [embedding] 491 tokens in 0.02s ‚Üí 26539.39 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 37645.44 tokens/sec\n",
      "üìä [embedding] 193 tokens in 0.04s ‚Üí 4810.21 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.02s ‚Üí 32226.54 tokens/sec\n",
      "üìä [embedding] 474 tokens in 0.02s ‚Üí 23906.35 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  13%|‚ñà‚ñà‚ñé               | 52/407 [00:02<00:10, 32.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 37 tokens in 0.05s ‚Üí 777.39 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.01s ‚Üí 34742.66 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 32059.68 tokens/sec\n",
      "üìä [embedding] 169 tokens in 0.05s ‚Üí 3491.59 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.01s ‚Üí 33442.69 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 35981.61 tokens/sec\n",
      "üìä [embedding] 223 tokens in 0.01s ‚Üí 15744.17 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.02s ‚Üí 27199.92 tokens/sec\n",
      "üìä [embedding] 471 tokens in 0.01s ‚Üí 36912.45 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  15%|‚ñà‚ñà‚ñã               | 60/407 [00:02<00:10, 33.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 58 tokens in 0.05s ‚Üí 1162.40 tokens/sec\n",
      "üìä [embedding] 496 tokens in 0.02s ‚Üí 31723.67 tokens/sec\n",
      "üìä [embedding] 281 tokens in 0.01s ‚Üí 20652.54 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.02s ‚Üí 27295.53 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 31478.37 tokens/sec\n",
      "üìä [embedding] 174 tokens in 0.05s ‚Üí 3858.44 tokens/sec\n",
      "üìä [embedding] 287 tokens in 0.05s ‚Üí 5293.44 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  17%|‚ñà‚ñà‚ñà               | 68/407 [00:02<00:11, 30.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 432 tokens in 0.02s ‚Üí 23575.46 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 34664.24 tokens/sec\n",
      "üìä [embedding] 112 tokens in 0.05s ‚Üí 2472.20 tokens/sec\n",
      "üìä [embedding] 455 tokens in 0.02s ‚Üí 29311.43 tokens/sec\n",
      "üìä [embedding] 472 tokens in 0.02s ‚Üí 21557.50 tokens/sec\n",
      "üìä [embedding] 160 tokens in 0.05s ‚Üí 3441.53 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.01s ‚Üí 37086.76 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  18%|‚ñà‚ñà‚ñà‚ñè              | 72/407 [00:02<00:10, 31.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 35426.06 tokens/sec\n",
      "üìä [embedding] 73 tokens in 0.05s ‚Üí 1474.31 tokens/sec\n",
      "üìä [embedding] 480 tokens in 0.02s ‚Üí 29426.40 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 30012.05 tokens/sec\n",
      "üìä [embedding] 64 tokens in 0.05s ‚Üí 1242.96 tokens/sec\n",
      "üìä [embedding] 453 tokens in 0.02s ‚Üí 27514.19 tokens/sec\n",
      "üìä [embedding] 484 tokens in 0.02s ‚Üí 28218.17 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  19%|‚ñà‚ñà‚ñà‚ñç              | 79/407 [00:03<00:12, 25.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 63 tokens in 0.13s ‚Üí 490.42 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.02s ‚Üí 27768.35 tokens/sec\n",
      "üìä [embedding] 489 tokens in 0.01s ‚Üí 37017.92 tokens/sec\n",
      "üìä [embedding] 89 tokens in 0.05s ‚Üí 1943.11 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.02s ‚Üí 23119.86 tokens/sec\n",
      "üìä [embedding] 490 tokens in 0.01s ‚Üí 42918.79 tokens/sec\n",
      "üìä [embedding] 462 tokens in 0.01s ‚Üí 40160.17 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  21%|‚ñà‚ñà‚ñà‚ñä              | 87/407 [00:03<00:10, 30.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 23 tokens in 0.04s ‚Üí 540.17 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.02s ‚Üí 20156.36 tokens/sec\n",
      "üìä [embedding] 474 tokens in 0.01s ‚Üí 36073.16 tokens/sec\n",
      "üìä [embedding] 478 tokens in 0.02s ‚Üí 31126.32 tokens/sec\n",
      "üìä [embedding] 488 tokens in 0.01s ‚Üí 40108.57 tokens/sec\n",
      "üìä [embedding] 493 tokens in 0.01s ‚Üí 38033.95 tokens/sec\n",
      "üìä [embedding] 478 tokens in 0.01s ‚Üí 31981.84 tokens/sec\n",
      "üìä [embedding] 477 tokens in 0.01s ‚Üí 36445.63 tokens/sec\n",
      "üìä [embedding] 478 tokens in 0.02s ‚Üí 23807.22 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  24%|‚ñà‚ñà‚ñà‚ñà‚ñè             | 96/407 [00:03<00:08, 34.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 431 tokens in 0.02s ‚Üí 21659.50 tokens/sec\n",
      "üìä [embedding] 480 tokens in 0.01s ‚Üí 37899.62 tokens/sec\n",
      "üìä [embedding] 477 tokens in 0.02s ‚Üí 28120.02 tokens/sec\n",
      "üìä [embedding] 338 tokens in 0.02s ‚Üí 16329.27 tokens/sec\n",
      "üìä [embedding] 486 tokens in 0.02s ‚Üí 21501.54 tokens/sec\n",
      "üìä [embedding] 496 tokens in 0.01s ‚Üí 36159.05 tokens/sec\n",
      "üìä [embedding] 480 tokens in 0.02s ‚Üí 22893.11 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  26%|‚ñà‚ñà‚ñà‚ñà‚ñç            | 105/407 [00:03<00:08, 37.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 10 tokens in 0.05s ‚Üí 193.61 tokens/sec\n",
      "üìä [embedding] 484 tokens in 0.01s ‚Üí 34653.02 tokens/sec\n",
      "üìä [embedding] 481 tokens in 0.01s ‚Üí 35727.50 tokens/sec\n",
      "üìä [embedding] 412 tokens in 0.01s ‚Üí 30311.94 tokens/sec\n",
      "üìä [embedding] 491 tokens in 0.01s ‚Üí 39132.07 tokens/sec\n",
      "üìä [embedding] 445 tokens in 0.01s ‚Üí 36556.50 tokens/sec\n",
      "üìä [embedding] 408 tokens in 0.01s ‚Üí 30050.86 tokens/sec\n",
      "üìä [embedding] 488 tokens in 0.02s ‚Üí 29887.13 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 42394.11 tokens/sec\n",
      "üìä [embedding] 450 tokens in 0.01s ‚Üí 36901.48 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  28%|‚ñà‚ñà‚ñà‚ñà‚ñä            | 114/407 [00:04<00:07, 38.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 70 tokens in 0.05s ‚Üí 1387.79 tokens/sec\n",
      "üìä [embedding] 476 tokens in 0.01s ‚Üí 34635.41 tokens/sec\n",
      "üìä [embedding] 466 tokens in 0.02s ‚Üí 30407.69 tokens/sec\n",
      "üìä [embedding] 438 tokens in 0.01s ‚Üí 29303.19 tokens/sec\n",
      "üìä [embedding] 481 tokens in 0.02s ‚Üí 31843.74 tokens/sec\n",
      "üìä [embedding] 491 tokens in 0.02s ‚Üí 30002.96 tokens/sec\n",
      "üìä [embedding] 482 tokens in 0.02s ‚Üí 30228.99 tokens/sec\n",
      "üìä [embedding] 26 tokens in 0.01s ‚Üí 3192.11 tokens/sec\n",
      "üìä [embedding] 465 tokens in 0.01s ‚Üí 33378.71 tokens/sec\n",
      "üìä [embedding] 482 tokens in 0.01s ‚Üí 35572.47 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 125/407 [00:04<00:06, 41.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 421 tokens in 0.01s ‚Üí 33378.11 tokens/sec\n",
      "üìä [embedding] 82 tokens in 0.05s ‚Üí 1790.47 tokens/sec\n",
      "üìä [embedding] 484 tokens in 0.02s ‚Üí 25327.42 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 32886.70 tokens/sec\n",
      "üìä [embedding] 446 tokens in 0.02s ‚Üí 26313.96 tokens/sec\n",
      "üìä [embedding] 93 tokens in 0.01s ‚Üí 11297.22 tokens/sec\n",
      "üìä [embedding] 487 tokens in 0.02s ‚Üí 30570.91 tokens/sec\n",
      "üìä [embedding] 475 tokens in 0.01s ‚Üí 32917.43 tokens/sec\n",
      "üìä [embedding] 386 tokens in 0.01s ‚Üí 28444.95 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 135/407 [00:04<00:06, 39.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 491 tokens in 0.02s ‚Üí 29997.28 tokens/sec\n",
      "üìä [embedding] 487 tokens in 0.02s ‚Üí 29410.19 tokens/sec\n",
      "üìä [embedding] 489 tokens in 0.01s ‚Üí 34024.80 tokens/sec\n",
      "üìä [embedding] 17 tokens in 0.05s ‚Üí 343.75 tokens/sec\n",
      "üìä [embedding] 471 tokens in 0.01s ‚Üí 36522.78 tokens/sec\n",
      "üìä [embedding] 490 tokens in 0.02s ‚Üí 32461.60 tokens/sec\n",
      "üìä [embedding] 425 tokens in 0.01s ‚Üí 33244.05 tokens/sec\n",
      "üìä [embedding] 489 tokens in 0.02s ‚Üí 32057.12 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 140/407 [00:04<00:08, 32.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 483 tokens in 0.02s ‚Üí 31988.77 tokens/sec\n",
      "üìä [embedding] 273 tokens in 0.02s ‚Üí 17946.29 tokens/sec\n",
      "üìä [embedding] 161 tokens in 0.05s ‚Üí 3164.55 tokens/sec\n",
      "üìä [embedding] 81 tokens in 0.05s ‚Üí 1709.37 tokens/sec\n",
      "üìä [embedding] 89 tokens in 0.05s ‚Üí 1808.61 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 144/407 [00:04<00:09, 27.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 85 tokens in 0.06s ‚Üí 1489.97 tokens/sec\n",
      "üìä [embedding] 4 tokens in 0.05s ‚Üí 73.63 tokens/sec\n",
      "üìä [embedding] 458 tokens in 0.02s ‚Üí 27769.62 tokens/sec\n",
      "üìä [embedding] 130 tokens in 0.05s ‚Üí 2588.87 tokens/sec\n",
      "üìä [embedding] 398 tokens in 0.02s ‚Üí 24530.26 tokens/sec\n",
      "üìä [embedding] 422 tokens in 0.01s ‚Üí 28469.35 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 152/407 [00:05<00:09, 27.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 237 tokens in 0.05s ‚Üí 4330.35 tokens/sec\n",
      "üìä [embedding] 393 tokens in 0.01s ‚Üí 28398.48 tokens/sec\n",
      "üìä [embedding] 329 tokens in 0.02s ‚Üí 19520.53 tokens/sec\n",
      "üìä [embedding] 383 tokens in 0.02s ‚Üí 22767.67 tokens/sec\n",
      "üìä [embedding] 107 tokens in 0.05s ‚Üí 2220.83 tokens/sec\n",
      "üìä [embedding] 119 tokens in 0.05s ‚Üí 2615.20 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 156/407 [00:05<00:10, 24.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 498 tokens in 0.02s ‚Üí 27303.74 tokens/sec\n",
      "üìä [embedding] 282 tokens in 0.01s ‚Üí 20638.16 tokens/sec\n",
      "üìä [embedding] 455 tokens in 0.01s ‚Üí 31938.28 tokens/sec\n",
      "üìä [embedding] 241 tokens in 0.11s ‚Üí 2269.30 tokens/sec\n",
      "üìä [embedding] 467 tokens in 0.02s ‚Üí 27036.49 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 163/407 [00:05<00:09, 26.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 332 tokens in 0.02s ‚Üí 20749.96 tokens/sec\n",
      "üìä [embedding] 485 tokens in 0.02s ‚Üí 29006.67 tokens/sec\n",
      "üìä [embedding] 113 tokens in 0.05s ‚Üí 2149.02 tokens/sec\n",
      "üìä [embedding] 342 tokens in 0.02s ‚Üí 19548.54 tokens/sec\n",
      "üìä [embedding] 264 tokens in 0.06s ‚Üí 4704.55 tokens/sec\n",
      "üìä [embedding] 384 tokens in 0.01s ‚Üí 26158.20 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 166/407 [00:05<00:09, 25.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 498 tokens in 0.01s ‚Üí 37343.36 tokens/sec\n",
      "üìä [embedding] 220 tokens in 0.05s ‚Üí 4127.81 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.02s ‚Üí 32649.17 tokens/sec\n",
      "üìä [embedding] 381 tokens in 0.02s ‚Üí 24996.95 tokens/sec\n",
      "üìä [embedding] 499 tokens in 0.01s ‚Üí 34356.97 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.02s ‚Üí 31387.79 tokens/sec\n",
      "üìä [embedding] 495 tokens in 0.02s ‚Üí 31442.51 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 176/407 [00:06<00:06, 34.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 498 tokens in 0.01s ‚Üí 33295.56 tokens/sec\n",
      "üìä [embedding] 471 tokens in 0.02s ‚Üí 30326.79 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.01s ‚Üí 34368.23 tokens/sec\n",
      "üìä [embedding] 465 tokens in 0.01s ‚Üí 36747.77 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 36466.50 tokens/sec\n",
      "üìä [embedding] 495 tokens in 0.01s ‚Üí 39179.13 tokens/sec\n",
      "üìä [embedding] 430 tokens in 0.02s ‚Üí 28522.30 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 36085.00 tokens/sec\n",
      "üìä [embedding] 473 tokens in 0.01s ‚Üí 35483.28 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 34489.80 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 186/407 [00:06<00:05, 39.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 469 tokens in 0.01s ‚Üí 32571.59 tokens/sec\n",
      "üìä [embedding] 467 tokens in 0.02s ‚Üí 29227.95 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 37056.74 tokens/sec\n",
      "üìä [embedding] 329 tokens in 0.01s ‚Üí 26296.83 tokens/sec\n",
      "üìä [embedding] 370 tokens in 0.01s ‚Üí 25524.13 tokens/sec\n",
      "üìä [embedding] 499 tokens in 0.02s ‚Üí 33046.35 tokens/sec\n",
      "üìä [embedding] 467 tokens in 0.01s ‚Üí 32919.45 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 35612.55 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 34556.29 tokens/sec\n",
      "üìä [embedding] 499 tokens in 0.01s ‚Üí 33810.28 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 196/407 [00:06<00:04, 42.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 32450.59 tokens/sec\n",
      "üìä [embedding] 464 tokens in 0.01s ‚Üí 31970.78 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 38711.41 tokens/sec\n",
      "üìä [embedding] 465 tokens in 0.01s ‚Üí 32453.93 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 33579.68 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.01s ‚Üí 36472.85 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 35696.81 tokens/sec\n",
      "üìä [embedding] 496 tokens in 0.02s ‚Üí 32791.24 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.01s ‚Üí 34587.33 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 35068.26 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 206/407 [00:06<00:04, 43.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 36194.61 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 37018.80 tokens/sec\n",
      "üìä [embedding] 479 tokens in 0.01s ‚Üí 32633.87 tokens/sec\n",
      "üìä [embedding] 476 tokens in 0.02s ‚Üí 30254.87 tokens/sec\n",
      "üìä [embedding] 315 tokens in 0.01s ‚Üí 21005.53 tokens/sec\n",
      "üìä [embedding] 413 tokens in 0.02s ‚Üí 27235.31 tokens/sec\n",
      "üìä [embedding] 477 tokens in 0.01s ‚Üí 32785.72 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.01s ‚Üí 35910.38 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 38793.04 tokens/sec\n",
      "üìä [embedding] 330 tokens in 0.01s ‚Üí 24186.49 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 216/407 [00:06<00:04, 44.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 401 tokens in 0.01s ‚Üí 32493.26 tokens/sec\n",
      "üìä [embedding] 419 tokens in 0.01s ‚Üí 32696.06 tokens/sec\n",
      "üìä [embedding] 434 tokens in 0.01s ‚Üí 32317.72 tokens/sec\n",
      "üìä [embedding] 478 tokens in 0.01s ‚Üí 33127.52 tokens/sec\n",
      "üìä [embedding] 424 tokens in 0.01s ‚Üí 30338.03 tokens/sec\n",
      "üìä [embedding] 474 tokens in 0.01s ‚Üí 34216.23 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 32404.96 tokens/sec\n",
      "üìä [embedding] 475 tokens in 0.01s ‚Üí 31885.38 tokens/sec\n",
      "üìä [embedding] 17 tokens in 0.01s ‚Üí 2121.55 tokens/sec\n",
      "üìä [embedding] 459 tokens in 0.01s ‚Üí 32391.99 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 226/407 [00:07<00:04, 40.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 489 tokens in 0.01s ‚Üí 36596.51 tokens/sec\n",
      "üìä [embedding] 58 tokens in 0.05s ‚Üí 1208.00 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.02s ‚Üí 29462.36 tokens/sec\n",
      "üìä [embedding] 496 tokens in 0.01s ‚Üí 34831.40 tokens/sec\n",
      "üìä [embedding] 187 tokens in 0.01s ‚Üí 16074.74 tokens/sec\n",
      "üìä [embedding] 490 tokens in 0.02s ‚Üí 27672.50 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 30694.22 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 231/407 [00:07<00:05, 34.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 232 tokens in 0.05s ‚Üí 4396.94 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.01s ‚Üí 36257.59 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 32495.34 tokens/sec\n",
      "üìä [embedding] 273 tokens in 0.05s ‚Üí 5594.73 tokens/sec\n",
      "üìä [embedding] 491 tokens in 0.01s ‚Üí 33412.89 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 34435.43 tokens/sec\n",
      "üìä [embedding] 411 tokens in 0.01s ‚Üí 32683.51 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.01s ‚Üí 35031.08 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 240/407 [00:07<00:05, 32.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 469 tokens in 0.02s ‚Üí 29615.62 tokens/sec\n",
      "üìä [embedding] 110 tokens in 0.05s ‚Üí 2317.20 tokens/sec\n",
      "üìä [embedding] 421 tokens in 0.02s ‚Üí 26926.74 tokens/sec\n",
      "üìä [embedding] 271 tokens in 0.01s ‚Üí 18232.01 tokens/sec\n",
      "üìä [embedding] 235 tokens in 0.05s ‚Üí 4666.41 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 244/407 [00:07<00:05, 27.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 225 tokens in 0.05s ‚Üí 4465.07 tokens/sec\n",
      "üìä [embedding] 73 tokens in 0.01s ‚Üí 8423.92 tokens/sec\n",
      "üìä [embedding] 199 tokens in 0.05s ‚Üí 3935.84 tokens/sec\n",
      "üìä [embedding] 192 tokens in 0.05s ‚Üí 3614.03 tokens/sec\n",
      "üìä [embedding] 204 tokens in 0.01s ‚Üí 14330.85 tokens/sec\n",
      "üìä [embedding] 241 tokens in 0.02s ‚Üí 10965.08 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 248/407 [00:08<00:05, 27.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 41 tokens in 0.01s ‚Üí 2953.43 tokens/sec\n",
      "üìä [embedding] 237 tokens in 0.05s ‚Üí 4358.86 tokens/sec\n",
      "üìä [embedding] 230 tokens in 0.06s ‚Üí 4169.07 tokens/sec\n",
      "üìä [embedding] 45 tokens in 0.05s ‚Üí 831.44 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 254/407 [00:08<00:05, 26.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 164 tokens in 0.01s ‚Üí 14919.87 tokens/sec\n",
      "üìä [embedding] 262 tokens in 0.01s ‚Üí 18001.89 tokens/sec\n",
      "üìä [embedding] 249 tokens in 0.05s ‚Üí 5208.44 tokens/sec\n",
      "üìä [embedding] 203 tokens in 0.01s ‚Üí 16125.22 tokens/sec\n",
      "üìä [embedding] 397 tokens in 0.01s ‚Üí 29433.45 tokens/sec\n",
      "üìä [embedding] 472 tokens in 0.01s ‚Üí 33702.38 tokens/sec\n",
      "üìä [embedding] 39 tokens in 0.01s ‚Üí 4738.09 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 263/407 [00:08<00:04, 31.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 146 tokens in 0.05s ‚Üí 3114.67 tokens/sec\n",
      "üìä [embedding] 345 tokens in 0.01s ‚Üí 23681.51 tokens/sec\n",
      "üìä [embedding] 390 tokens in 0.02s ‚Üí 23413.42 tokens/sec\n",
      "üìä [embedding] 322 tokens in 0.01s ‚Üí 24580.32 tokens/sec\n",
      "üìä [embedding] 451 tokens in 0.01s ‚Üí 30833.43 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 37151.93 tokens/sec\n",
      "üìä [embedding] 54 tokens in 0.05s ‚Üí 1050.13 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 271/407 [00:08<00:04, 30.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 376 tokens in 0.02s ‚Üí 21948.70 tokens/sec\n",
      "üìä [embedding] 413 tokens in 0.02s ‚Üí 26631.53 tokens/sec\n",
      "üìä [embedding] 476 tokens in 0.01s ‚Üí 35194.06 tokens/sec\n",
      "üìä [embedding] 441 tokens in 0.01s ‚Üí 34220.53 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 34561.98 tokens/sec\n",
      "üìä [embedding] 10 tokens in 0.06s ‚Üí 180.31 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 36051.50 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç     | 275/407 [00:08<00:04, 30.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 10 tokens in 0.05s ‚Üí 192.88 tokens/sec\n",
      "üìä [embedding] 417 tokens in 0.01s ‚Üí 27980.81 tokens/sec\n",
      "üìä [embedding] 487 tokens in 0.02s ‚Üí 30093.05 tokens/sec\n",
      "üìä [embedding] 465 tokens in 0.02s ‚Üí 30942.24 tokens/sec\n",
      "üìä [embedding] 482 tokens in 0.02s ‚Üí 31128.72 tokens/sec\n",
      "üìä [embedding] 497 tokens in 0.01s ‚Üí 40376.72 tokens/sec\n",
      "üìä [embedding] 37 tokens in 0.06s ‚Üí 671.17 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 282/407 [00:09<00:04, 28.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 475 tokens in 0.02s ‚Üí 29124.98 tokens/sec\n",
      "üìä [embedding] 414 tokens in 0.02s ‚Üí 27528.49 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 28866.91 tokens/sec\n",
      "üìä [embedding] 28 tokens in 0.05s ‚Üí 541.72 tokens/sec\n",
      "üìä [embedding] 392 tokens in 0.02s ‚Üí 25941.42 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 31623.14 tokens/sec\n",
      "üìä [embedding] 398 tokens in 0.02s ‚Üí 26468.36 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 292/407 [00:09<00:03, 36.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 486 tokens in 0.02s ‚Üí 29968.12 tokens/sec\n",
      "üìä [embedding] 491 tokens in 0.01s ‚Üí 34106.81 tokens/sec\n",
      "üìä [embedding] 495 tokens in 0.01s ‚Üí 37115.08 tokens/sec\n",
      "üìä [embedding] 435 tokens in 0.01s ‚Üí 35371.98 tokens/sec\n",
      "üìä [embedding] 403 tokens in 0.01s ‚Üí 33911.90 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 41525.30 tokens/sec\n",
      "üìä [embedding] 17 tokens in 0.01s ‚Üí 2118.34 tokens/sec\n",
      "üìä [embedding] 499 tokens in 0.01s ‚Üí 38757.04 tokens/sec\n",
      "üìä [embedding] 7 tokens in 0.05s ‚Üí 142.16 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 300/407 [00:09<00:03, 34.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 460 tokens in 0.01s ‚Üí 31364.89 tokens/sec\n",
      "üìä [embedding] 351 tokens in 0.01s ‚Üí 27202.53 tokens/sec\n",
      "üìä [embedding] 484 tokens in 0.01s ‚Üí 35937.60 tokens/sec\n",
      "üìä [embedding] 387 tokens in 0.01s ‚Üí 31295.34 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.01s ‚Üí 40776.25 tokens/sec\n",
      "üìä [embedding] 19 tokens in 0.05s ‚Üí 412.10 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 31753.86 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 304/407 [00:09<00:03, 32.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 12 tokens in 0.05s ‚Üí 233.56 tokens/sec\n",
      "üìä [embedding] 448 tokens in 0.02s ‚Üí 28076.92 tokens/sec\n",
      "üìä [embedding] 394 tokens in 0.01s ‚Üí 27761.45 tokens/sec\n",
      "üìä [embedding] 441 tokens in 0.01s ‚Üí 29823.10 tokens/sec\n",
      "üìä [embedding] 442 tokens in 0.02s ‚Üí 25322.46 tokens/sec\n",
      "üìä [embedding] 390 tokens in 0.01s ‚Üí 30518.83 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.01s ‚Üí 40100.66 tokens/sec\n",
      "üìä [embedding] 31 tokens in 0.05s ‚Üí 666.69 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 313/407 [00:10<00:02, 33.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 482 tokens in 0.02s ‚Üí 31181.05 tokens/sec\n",
      "üìä [embedding] 398 tokens in 0.02s ‚Üí 25762.11 tokens/sec\n",
      "üìä [embedding] 438 tokens in 0.01s ‚Üí 30674.66 tokens/sec\n",
      "üìä [embedding] 492 tokens in 0.01s ‚Üí 34577.13 tokens/sec\n",
      "üìä [embedding] 455 tokens in 0.01s ‚Üí 31612.39 tokens/sec\n",
      "üìä [embedding] 396 tokens in 0.01s ‚Üí 27308.73 tokens/sec\n",
      "üìä [embedding] 495 tokens in 0.02s ‚Üí 31574.97 tokens/sec\n",
      "üìä [embedding] 453 tokens in 0.01s ‚Üí 30678.14 tokens/sec\n",
      "üìä [embedding] 490 tokens in 0.02s ‚Üí 32629.62 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 322/407 [00:10<00:02, 33.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 32807.98 tokens/sec\n",
      "üìä [embedding] 2 tokens in 0.05s ‚Üí 39.19 tokens/sec\n",
      "üìä [embedding] 430 tokens in 0.02s ‚Üí 28258.19 tokens/sec\n",
      "üìä [embedding] 491 tokens in 0.02s ‚Üí 30798.96 tokens/sec\n",
      "üìä [embedding] 395 tokens in 0.01s ‚Üí 26456.36 tokens/sec\n",
      "üìä [embedding] 446 tokens in 0.01s ‚Üí 32056.54 tokens/sec\n",
      "üìä [embedding] 354 tokens in 0.01s ‚Üí 28334.48 tokens/sec\n",
      "üìä [embedding] 446 tokens in 0.01s ‚Üí 33856.87 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 332/407 [00:10<00:02, 37.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 447 tokens in 0.01s ‚Üí 32937.82 tokens/sec\n",
      "üìä [embedding] 455 tokens in 0.01s ‚Üí 31081.57 tokens/sec\n",
      "üìä [embedding] 426 tokens in 0.02s ‚Üí 28379.50 tokens/sec\n",
      "üìä [embedding] 369 tokens in 0.01s ‚Üí 27899.52 tokens/sec\n",
      "üìä [embedding] 471 tokens in 0.01s ‚Üí 37040.48 tokens/sec\n",
      "üìä [embedding] 411 tokens in 0.01s ‚Üí 29460.12 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 36052.12 tokens/sec\n",
      "üìä [embedding] 9 tokens in 0.01s ‚Üí 1218.37 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 36940.55 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 340/407 [00:10<00:01, 34.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 49 tokens in 0.05s ‚Üí 1052.97 tokens/sec\n",
      "üìä [embedding] 437 tokens in 0.01s ‚Üí 29945.61 tokens/sec\n",
      "üìä [embedding] 493 tokens in 0.02s ‚Üí 32379.57 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 33029.66 tokens/sec\n",
      "üìä [embedding] 27 tokens in 0.05s ‚Üí 560.89 tokens/sec\n",
      "üìä [embedding] 423 tokens in 0.02s ‚Üí 26765.29 tokens/sec\n",
      "üìä [embedding] 360 tokens in 0.01s ‚Üí 24479.98 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 349/407 [00:11<00:01, 36.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 494 tokens in 0.01s ‚Üí 38026.47 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 38461.50 tokens/sec\n",
      "üìä [embedding] 16 tokens in 0.01s ‚Üí 2005.52 tokens/sec\n",
      "üìä [embedding] 330 tokens in 0.01s ‚Üí 24619.28 tokens/sec\n",
      "üìä [embedding] 487 tokens in 0.02s ‚Üí 31646.54 tokens/sec\n",
      "üìä [embedding] 431 tokens in 0.01s ‚Üí 33887.17 tokens/sec\n",
      "üìä [embedding] 437 tokens in 0.02s ‚Üí 28946.33 tokens/sec\n",
      "üìä [embedding] 475 tokens in 0.02s ‚Üí 26820.69 tokens/sec\n",
      "üìä [embedding] 498 tokens in 0.02s ‚Üí 31513.28 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 358/407 [00:11<00:01, 34.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 12 tokens in 0.07s ‚Üí 175.72 tokens/sec\n",
      "üìä [embedding] 438 tokens in 0.02s ‚Üí 28268.81 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 32794.13 tokens/sec\n",
      "üìä [embedding] 39 tokens in 0.01s ‚Üí 4756.69 tokens/sec\n",
      "üìä [embedding] 422 tokens in 0.02s ‚Üí 27333.32 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 31673.77 tokens/sec\n",
      "üìä [embedding] 8 tokens in 0.01s ‚Üí 947.44 tokens/sec\n",
      "üìä [embedding] 354 tokens in 0.02s ‚Üí 23366.23 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 32031.28 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 366/407 [00:11<00:01, 30.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 8 tokens in 0.06s ‚Üí 126.43 tokens/sec\n",
      "üìä [embedding] 453 tokens in 0.02s ‚Üí 28023.48 tokens/sec\n",
      "üìä [embedding] 379 tokens in 0.01s ‚Üí 27026.44 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 34103.91 tokens/sec\n",
      "üìä [embedding] 52 tokens in 0.06s ‚Üí 920.03 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 33634.08 tokens/sec\n",
      "üìä [embedding] 27 tokens in 0.01s ‚Üí 3422.47 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 376/407 [00:11<00:00, 35.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 439 tokens in 0.01s ‚Üí 30735.97 tokens/sec\n",
      "üìä [embedding] 418 tokens in 0.01s ‚Üí 28913.35 tokens/sec\n",
      "üìä [embedding] 481 tokens in 0.01s ‚Üí 32257.69 tokens/sec\n",
      "üìä [embedding] 454 tokens in 0.01s ‚Üí 32819.96 tokens/sec\n",
      "üìä [embedding] 309 tokens in 0.01s ‚Üí 24431.00 tokens/sec\n",
      "üìä [embedding] 463 tokens in 0.01s ‚Üí 37374.91 tokens/sec\n",
      "üìä [embedding] 464 tokens in 0.01s ‚Üí 31521.82 tokens/sec\n",
      "üìä [embedding] 399 tokens in 0.01s ‚Üí 34266.91 tokens/sec\n",
      "üìä [embedding] 387 tokens in 0.01s ‚Üí 31409.19 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 380/407 [00:12<00:00, 32.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 487 tokens in 0.01s ‚Üí 41841.66 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.01s ‚Üí 39147.88 tokens/sec\n",
      "üìä [embedding] 20 tokens in 0.07s ‚Üí 306.03 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 29300.88 tokens/sec\n",
      "üìä [embedding] 10 tokens in 0.01s ‚Üí 1231.41 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 29581.93 tokens/sec\n",
      "üìä [embedding] 28 tokens in 0.01s ‚Üí 3130.58 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 389/407 [00:12<00:00, 34.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 31983.41 tokens/sec\n",
      "üìä [embedding] 37 tokens in 0.01s ‚Üí 4467.03 tokens/sec\n",
      "üìä [embedding] 295 tokens in 0.02s ‚Üí 17571.07 tokens/sec\n",
      "üìä [embedding] 379 tokens in 0.01s ‚Üí 26616.90 tokens/sec\n",
      "üìä [embedding] 454 tokens in 0.01s ‚Üí 31913.49 tokens/sec\n",
      "üìä [embedding] 500 tokens in 0.02s ‚Üí 31420.36 tokens/sec\n",
      "üìä [embedding] 19 tokens in 0.01s ‚Üí 2377.94 tokens/sec\n",
      "üìä [embedding] 470 tokens in 0.02s ‚Üí 29354.82 tokens/sec\n",
      "üìä [embedding] 460 tokens in 0.01s ‚Üí 33951.22 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 393/407 [00:12<00:00, 35.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 491 tokens in 0.02s ‚Üí 31751.03 tokens/sec\n",
      "üìä [embedding] 240 tokens in 0.07s ‚Üí 3644.42 tokens/sec\n",
      "üìä [embedding] 454 tokens in 0.01s ‚Üí 30335.40 tokens/sec\n",
      "üìä [embedding] 294 tokens in 0.01s ‚Üí 20457.64 tokens/sec\n",
      "üìä [embedding] 75 tokens in 0.06s ‚Üí 1314.34 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 401/407 [00:12<00:00, 30.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 386 tokens in 0.02s ‚Üí 24373.37 tokens/sec\n",
      "üìä [embedding] 499 tokens in 0.02s ‚Üí 30182.25 tokens/sec\n",
      "üìä [embedding] 457 tokens in 0.01s ‚Üí 34237.08 tokens/sec\n",
      "üìä [embedding] 286 tokens in 0.02s ‚Üí 18859.10 tokens/sec\n",
      "üìä [embedding] 166 tokens in 0.06s ‚Üí 2756.93 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Storing in ChromaDB: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 407/407 [00:13<00:00, 31.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 86 tokens in 0.06s ‚Üí 1463.61 tokens/sec\n",
      "üìä [embedding] 273 tokens in 0.06s ‚Üí 4584.67 tokens/sec\n",
      "üìä [embedding] 138 tokens in 0.06s ‚Üí 2397.84 tokens/sec\n",
      "üìä [embedding] 4 tokens in 0.01s ‚Üí 508.99 tokens/sec\n",
      "üìä [embedding] 6 tokens in 0.01s ‚Üí 801.61 tokens/sec\n",
      "‚úÖ Chunks stored in ChromaDB using local embeddings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [embedding] 5 tokens in 0.06s ‚Üí 79.78 tokens/sec\n",
      "üìä [RAG] 446 tokens in 51.23s ‚Üí 8.71 tokens/sec\n",
      "ü§ñ Mistral says:\n",
      "  Emotional Intelligence (EI) refers to the ability to identify, use, understand, and manage emotions in positive ways to relieve stress, communicate effectively, empathize with others, overcome challenges, and defuse conflict. It involves self-awareness, self-regulation, motivation, empathy, and social skills (Goleman, 2011).\n",
      "\n",
      "EI can be distinguished from Intelligence Quotient (IQ) as the latter measures cognitive abilities such as problem-solving, reasoning, and logic. EI is more concerned with emotional and interpersonal skills that affect how we interact with others and manage our own emotions effectively (Verywell Mind, 2023).\n",
      "\n",
      "In this course, Computer Assisted Research Skills (CARS), students will not directly study EI as the primary focus. However, it is essential to note that understanding the basics of EI can provide valuable insights while conducting research and analyzing data using tools such as SPSS. By gaining familiarity with statistical tests and interpreting data output in SPSS, students may indirectly improve their EI through better data analysis and interpretation skills (Trainer Bubble, 2019; Elearning Industry, 2023).\n",
      "\n",
      "To further investigate the science behind EI, students are encouraged to engage in self-study activities, such as reading literature on the topic, measuring emotional intelligence, identifying happy people, and understanding the difference between EQ and IQ (Web Sources provided). Additionally, there are online courses available on platforms like Coursera that focus on emotional and social intelligence (Coursera, 2023; Positive Psychology, 2023).\n",
      "\n",
      "Moreover, the construction of a simple emotional intelligence assessment can help students measure their own EI levels and identify areas for improvement. This self-awareness is an essential aspect of developing emotional intelligence (Ali Abdal, 2018). The process of creating such an assessment can also serve as a practical application of skills learned in the CARS course.\n",
      "\n",
      "In summary, while this specific course does not focus on EI directly, it offers opportunities for students to indirectly develop their EI through data analysis and interpretation using tools like SPSS. Additionally, self-study activities and online courses focused on emotional intelligence can help students gain a deeper understanding of the topic. Constructing an emotional intelligence assessment can also serve as a practical application of research skills learned in the CARS course.\n"
     ]
    }
   ],
   "source": [
    "clean_df= clean_dataframe_text(df)\n",
    "store_df_in_chromadb_local(clean_df)\n",
    "response = rag_query(\"what is Emotional intelligence?\")\n",
    "print(\"ü§ñ Mistral says:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9714b028-beec-4c76-83e0-b530ee029bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# ========== Evaluate Summaries with ROUGE ==========\n",
    "def evaluate_summaries_with_rouge(generated_summaries: dict, reference_summaries: dict):\n",
    "    \"\"\"\n",
    "    Compare generated summaries to reference summaries using ROUGE scores.\n",
    "    \"\"\"\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    evaluation = {}\n",
    "\n",
    "    for doc_id, generated in tqdm(generated_summaries.items(), desc=\"üìè Evaluating ROUGE\"):\n",
    "        reference = reference_summaries.get(doc_id, \"\")\n",
    "        if not reference:\n",
    "            print(f\"‚ö†Ô∏è No reference summary found for document: {doc_id}\")\n",
    "            continue\n",
    "\n",
    "        scores = scorer.score(generated, reference)\n",
    "        evaluation[doc_id] = {\n",
    "            metric: {\n",
    "                \"precision\": round(scores[metric].precision, 4),\n",
    "                \"recall\": round(scores[metric].recall, 4),\n",
    "                \"f1\": round(scores[metric].fmeasure, 4)\n",
    "            } for metric in scores\n",
    "        }\n",
    "\n",
    "    return evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f06998-7317-427b-b29c-b89aec72bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = summarize_all_documents()\n",
    "# response = rag_query(\"Tell me about Emotional Intelligence\")\n",
    "\n",
    "print(\"ü§ñ Mistral says:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a410b7b-45c4-46e3-839a-e99cf7cef764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Summarizing files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:24<00:00, 24.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä [RAG] 679 tokens in 24.68s ‚Üí 27.51 tokens/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üìè Evaluating ROUGE: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 62.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROUGE Scores for: Dataset summaries and citations.docx\n",
      "\n",
      "Metric     Precision  Recall     F1 Score  \n",
      "ROUGE1     0.3833     0.5337     0.4462    \n",
      "ROUGE2     0.1150     0.1605     0.1340    \n",
      "ROUGEL     0.1674     0.2331     0.1949    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ========== Preloaded Reference Summaries ==========\n",
    "reference_summaries = {\n",
    "    \"Dataset summaries and citations.docx\": \"\"\"\n",
    "    1. Numerous studies have investigated carbon accumulation and nitrogen cycling in various urban land uses including residential soils, golf courses, and home lawns.\n",
    "    2. Some research emphasizes specific biophysical factors influencing soil carbon, such as:\n",
    "       - Microbial processes (e.g., Shi et al., 2012),\n",
    "       - Management intensity and duration (e.g., Wang et al., 2014),\n",
    "       - Historical land use changes (e.g., Raccanello et al., 2011).\n",
    "    3. A subset of studies analyzes regional influences on carbon sequestration, examining how soil characteristics and climatic conditions affect carbon dynamics in urban ecosystems (e.g., Selhorst & Lal, 2011; Smith et al., 2018).\n",
    "    4. Comparative assessments have been conducted to evaluate differences in carbon sequestration across urban land typologies, including turfgrass systems and residential zones with varied development histories.\n",
    "    5. Findings indicate that urban landscapes can serve as significant carbon sinks, occasionally surpassing the sequestration potential of rural or forested lands (Selhorst & Lal, 2011; Trammell et al., 2020).\n",
    "    6. Despite their potential benefits, urban environments also contribute to greenhouse gas emissions, especially from impervious surfaces and vehicular traffic (Townsend-Small & Czimczik, 2010).\n",
    "    7. Research suggests that residential lawns have a variable carbon sequestration potential, heavily influenced by climate, management practices, and underlying soil properties.\n",
    "    8. In conclusion, while urban landscapes offer valuable opportunities for climate change mitigation through carbon storage, maximizing their potential requires integrated land management strategies that simultaneously limit greenhouse gas emissions.\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# ========== Example Evaluation Run ==========\n",
    "generated_summaries = summarize_all_documents()\n",
    "results = evaluate_summaries_with_rouge(generated_summaries, reference_summaries)\n",
    "data = results\n",
    "for filename, scores in data.items():\n",
    "    print(f\"\\nROUGE Scores for: {filename}\\n\")\n",
    "    print(f\"{'Metric':<10} {'Precision':<10} {'Recall':<10} {'F1 Score':<10}\")\n",
    "    for metric, values in scores.items():\n",
    "        print(f\"{metric.upper():<10} {values['precision']:<10.4f} {values['recall']:<10.4f} {values['f1']:<10.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e13c95f-23bb-4c70-ab68-8d6b2f1de756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07f8920-98a9-495a-8395-2d6e9638bdda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d03221-80cf-48df-8a9f-d62e23fdf2b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc75ab1-f5d5-4e02-97d0-d160de9022c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ffdd9f-c3a7-48a3-90a9-1592f09cbc63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45e5704-497d-494a-a4ca-c3858d940a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6536e37-a4ac-4615-b687-0359254d34d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5abf44-2251-49a1-9b38-9b45d53884db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc11a8ab-090c-40b0-a7d4-006bc40ccff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_all_documents(collection_name=\"docs\", persist_dir=\"./chroma_storage\", max_chunks=5):\n",
    "    \"\"\"\n",
    "    Summarize a limited number of stored chunks to reduce load and return a list of summaries.\n",
    "    \"\"\"\n",
    "    chroma_client = chromadb.PersistentClient(path=persist_dir)\n",
    "    collection = chroma_client.get_or_create_collection(name=collection_name)\n",
    "\n",
    "    results = collection.get(include=[\"documents\"])\n",
    "    all_chunks = results.get(\"documents\", [])\n",
    "\n",
    "    print(f\"üß† Summarizing up to {max_chunks} chunks...\")\n",
    "    summaries = []\n",
    "    for idx, chunk in enumerate(all_chunks[:max_chunks]):\n",
    "        if isinstance(chunk, str) and chunk.strip():\n",
    "            summary = ask_mistral(\"Summarize the following document chunk.\", chunk)\n",
    "            summaries.append(summary)\n",
    "\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98dbf52-d72c-45a7-8b36-534b01fc1a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load once\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def embed_texts_local(texts):\n",
    "    \"\"\"Embed text using a local SentenceTransformer model.\"\"\"\n",
    "    return embed_model.encode(texts).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efe11e6-b680-4ae7-9fcf-85c9b73bd798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import pandas as pd\n",
    "\n",
    "def store_df_in_chromadb_local(df, persist_dir=\"./chroma_storage\", collection_name=\"drx_docs\"):\n",
    "    chroma_client = chromadb.PersistentClient(path=persist_dir)\n",
    "    collection = chroma_client.get_or_create_collection(name=collection_name)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        doc_id = f\"{row['file_name']}_{row['page_number']}_{row['chunk_number']}\"\n",
    "        try:\n",
    "            embedding = embed_texts_local([row['text']])[0]\n",
    "            collection.add(\n",
    "                documents=[row['text']],\n",
    "                ids=[doc_id],\n",
    "                metadatas=[{\n",
    "                    \"file_name\": row['file_name'],\n",
    "                    \"page\": row['page_number'],\n",
    "                    \"chunk\": row['chunk_number']\n",
    "                }],\n",
    "                embeddings=[embedding]\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error at row {idx}: {e}\")\n",
    "    print(\"‚úÖ Chunks stored in ChromaDB using local embeddings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f891cb9b-ddab-43f4-ac33-544d32928342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_chromadb_local(question, collection_name=\"drx_docs\", persist_dir=\"./chroma_storage\", top_k=1):\n",
    "    chroma_client = chromadb.PersistentClient(path=persist_dir)\n",
    "    collection = chroma_client.get_or_create_collection(name=collection_name)\n",
    "\n",
    "    query_vector = embed_texts_local([question])[0]\n",
    "    results = collection.query(query_embeddings=[query_vector], n_results=top_k)\n",
    "    # print(results)\n",
    "\n",
    "    for doc, meta in zip(results[\"documents\"][0], results[\"metadatas\"][0]):\n",
    "        print(f\"üìÑ {meta['file_name']} (Page {meta['page']}, Chunk {meta['chunk']})\")\n",
    "        print(doc)\n",
    "        print(\"------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a414e3b2-3f97-4775-ad88-fff8d24ad777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def ask_mistral(question, context):\n",
    "    prompt = f\"\"\"Answer the question based on the context below.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model=\"mistral\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072137e2-017a-41ee-ab51-c3731bf3f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_query(question, collection_name=\"drx_docs\", persist_dir=\"./chroma_storage\", top_k=5):\n",
    "    # Embed the question\n",
    "    query_vector = embed_texts_local([question])[0]\n",
    "\n",
    "    # Query ChromaDB\n",
    "    chroma_client = chromadb.PersistentClient(path=persist_dir)\n",
    "    collection = chroma_client.get_or_create_collection(name=collection_name)\n",
    "    results = collection.query(query_embeddings=[query_vector], n_results=top_k)\n",
    "\n",
    "    # Concatenate top chunks\n",
    "    retrieved_chunks = results[\"documents\"][0]\n",
    "    context = \"\\n\\n\".join(retrieved_chunks)\n",
    "\n",
    "    # Generate answer with Ollama Mistral\n",
    "    answer = ask_mistral(question, context)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447aa36d-b33f-42ee-ba07-b1c8a1a79cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_query(\"summarize all papers?\")\n",
    "print(\"ü§ñ Mistral says:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5da8b2-4504-41a3-bfcf-827d526c16a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca069ad9-dfef-4dde-9c41-51e71e92e430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003d2f6-a141-41e4-a1d6-12c33842a401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb892274-b3c5-49f5-899c-96aad5d43917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
